{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе. Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании вы:\n",
    "\n",
    "потренируетесь считать градиенты различных многомерных функций\n",
    "реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "реализуете процесс тренировки линейного классификатора\n",
    "подберете параметры тренировки на практике\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:\n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6529/3741198026.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
      "/tmp/ipykernel_6529/3741198026.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic_grad  [6.]\n",
      "analytic_grad_at_ix  6.0\n",
      "it value is  3.0\n",
      "ix  (0,)\n",
      "zero arr is  [1.e-05]\n",
      "func1 is  8.999940000099999\n",
      "func2 is  9.0000600001\n",
      "numeric_grad_at_ix  6.000000000039306\n",
      "Gradient check passed!\n",
      "analytic_grad  [1. 1.]\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  3.0\n",
      "ix  (0,)\n",
      "zero arr is  [1.e-05 0.e+00]\n",
      "func1 is  4.99999\n",
      "func2 is  5.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  2.0\n",
      "ix  (1,)\n",
      "zero arr is  [0.e+00 1.e-05]\n",
      "func1 is  4.99999\n",
      "func2 is  5.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "Gradient check passed!\n",
      "analytic_grad  [[1. 1.]\n",
      " [1. 1.]]\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  3.0\n",
      "ix  (0, 0)\n",
      "zero arr is  [[1.e-05 0.e+00]\n",
      " [0.e+00 0.e+00]]\n",
      "func1 is  5.99999\n",
      "func2 is  6.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  2.0\n",
      "ix  (0, 1)\n",
      "zero arr is  [[0.e+00 1.e-05]\n",
      " [0.e+00 0.e+00]]\n",
      "func1 is  5.99999\n",
      "func2 is  6.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  1.0\n",
      "ix  (1, 0)\n",
      "zero arr is  [[0.e+00 0.e+00]\n",
      " [1.e-05 0.e+00]]\n",
      "func1 is  5.99999\n",
      "func2 is  6.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "analytic_grad_at_ix  1.0\n",
      "it value is  0.0\n",
      "ix  (1, 1)\n",
      "zero arr is  [[0.e+00 0.e+00]\n",
      " [0.e+00 1.e-05]]\n",
      "func1 is  5.99999\n",
      "func2 is  6.00001\n",
      "numeric_grad_at_ix  0.9999999999621422\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "90\n",
      "5\n",
      "[[ True  True False  True]\n",
      " [ True False False False]]\n",
      "(1, 0)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[3,2,4,5], [3,3,2,1]])\n",
    "b = np.array([3,2,90,5])\n",
    "for elem in b:\n",
    "    print(elem)\n",
    "\n",
    "check = np.isclose(a, b, atol=0.5)\n",
    "print(check)\n",
    "\n",
    "\n",
    "it = np.nditer(a, flags=['multi_index'], op_flags=['readwrite'])\n",
    "ix = it.multi_index\n",
    "it.iternext()\n",
    "it.iternext()\n",
    "it.iternext()\n",
    "it.iternext()\n",
    "# it.()\n",
    "print(it.multi_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Задание 3.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
    "\n",
    "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.  \n",
    "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
    "from model import ConvNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные\n",
    "\n",
    "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности `(num_samples, 32, 32, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):    \n",
    "    train_X = train_X.astype(float) / 255.0\n",
    "    test_X = test_X.astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_X, axis = 0)\n",
    "    train_X -= mean_image\n",
    "    test_X -= mean_image\n",
    "    \n",
    "    return train_X, test_X\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуем новые слои!\n",
    "Сначала основной новый слой - сверточный (Convolutional layer). Для начала мы реализуем его для только одного канала, а потом для нескольких.\n",
    "\n",
    "Сверточный слой выполняет операцию свертки (convolution) с весами для каждого канала, а потом складывает результаты. Возможно, поможет пересмотреть Лекцию 6 или внимательно прочитать http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Один из подходов к реализации сверточного слоя основан на том, что для конкретного \"пикселя\" выхода применение сверточного слоя эквивалентно обычному полносвязному.\n",
    "\n",
    "![Getting Started](conv_img.jpg)\n",
    "\n",
    "Рассмотрим один такой \"пиксель\":\n",
    "\n",
    "Он получает на вход  \n",
    "регион входа I размера `(batch_size, filter_size, filter_size, input_channels)`,\n",
    "\n",
    "применяет к нему веса W `(filter_size, filter_size, input_channels, output_channels` и выдает `(batch_size, output_channels)`.\n",
    "\n",
    "Если:  \n",
    "* вход преобразовать в I' `(batch_size, filter_size*filter_size*input_channels)`,  \n",
    "* веса в W' `(filter_size*filter_size*input_channels, output_channels)`,\n",
    "\n",
    "то выход \"пикселе\" будет эквивалентен полносвязному слою со входом I' и весами W'.  \n",
    "Осталось выполнить его в цикле для каждого пикселя :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2, 2, 2, 1)\n",
      "Shape of W (2, 2, 1, 1)\n",
      "Shape of X: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
    "\n",
    "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
    "# (batch_size, height, width, channels)\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0], [2.0]],\n",
    "               [[0.0], [-1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0], [1.0]],\n",
    "               [[-2.0], [-1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# Batch of 2 images of dimensions 2x2 with a single channel\n",
    "print(\"Shape of X:\",X.shape)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
    "print(\"Shape of W\", layer.W.value.shape)\n",
    "layer.W.value = np.zeros_like(layer.W.value)\n",
    "layer.W.value[0, 0, 0, 0] = 1.0\n",
    "layer.B.value = np.ones_like(layer.B.value)\n",
    "result = layer.forward(X)\n",
    "\n",
    "assert result.shape == (2, 1, 1, 1)\n",
    "assert np.all(result == X[:, :1, :1, :1] +1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
    "\n",
    "\n",
    "# Now let's implement multiple output channels\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "\n",
    "# And now multple input channels!\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь имплементируем обратный проход\n",
    "\n",
    "Возможно, это самое сложное место в курсе. Дальше будет лучше.\n",
    "\n",
    "Раз выполнение сверточного слоя эквивалентно полносвязному слою для каждого \"пикселя\" выхода, то общий обратный проход эквивалентен обратному проходу каждого из таких \"слоев\".  \n",
    "Градиенты от каждого из этих \"слоев\" в каждом пикселе надо сложить в соответствующие пиксели градиента по входу, а градиенты весов сложить все вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 1.  0.]\n",
      "   [ 2.  1.]]\n",
      "\n",
      "  [[ 0. -1.]\n",
      "   [-1. -2.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.]\n",
      "   [ 1. -1.]]\n",
      "\n",
      "  [[-2.  2.]\n",
      "   [-1.  0.]]]]\n",
      "analytic grad is \n",
      " [[[[-1.2342309  -0.09028112]\n",
      "   [-0.2320982  -0.97687821]]\n",
      "\n",
      "  [[ 2.35547367  0.34562644]\n",
      "   [ 0.74214092 -1.34064914]]]\n",
      "\n",
      "\n",
      " [[[-1.77790396 -1.86222897]\n",
      "   [ 1.28985452 -0.07319631]]\n",
      "\n",
      "  [[ 0.35319401 -0.98034809]\n",
      "   [ 0.25882111  0.23274385]]]]\n",
      "numeric grad array is \n",
      " [[[[-1.2342309  -0.09028112]\n",
      "   [-0.2320982  -0.97687821]]\n",
      "\n",
      "  [[ 2.35547367  0.34562644]\n",
      "   [ 0.74214092 -1.34064914]]]\n",
      "\n",
      "\n",
      " [[[-1.77790396 -1.86222897]\n",
      "   [ 1.28985452 -0.07319631]]\n",
      "\n",
      "  [[ 0.35319401 -0.98034809]\n",
      "   [ 0.25882111  0.23274385]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 0.09920486  1.57629897]\n",
      "   [ 0.50232824 -0.862267  ]]\n",
      "\n",
      "  [[ 0.16066119 -0.95264495]\n",
      "   [ 1.60852216 -0.56157875]]]\n",
      "\n",
      "\n",
      " [[[ 0.20727075  0.30773257]\n",
      "   [ 0.15925047 -1.95854896]]\n",
      "\n",
      "  [[-1.44642106 -0.45235028]\n",
      "   [ 0.31943183 -0.13777921]]]]\n",
      "analytic grad is \n",
      " [[[[-0.95714747 -1.34842432]\n",
      "   [-0.40155754 -0.46847604]]\n",
      "\n",
      "  [[-2.31585249 -3.16532468]\n",
      "   [-0.55558993 -0.87994827]]]\n",
      "\n",
      "\n",
      " [[[ 0.80311509  0.93695209]\n",
      "   [ 0.15403238  0.41147223]]\n",
      "\n",
      "  [[ 1.35870502  1.81690036]\n",
      "   [ 1.91429495  2.69684864]]]]\n",
      "numeric grad array is \n",
      " [[[[-0.95714747 -1.34842432]\n",
      "   [-0.40155754 -0.46847604]]\n",
      "\n",
      "  [[-2.31585249 -3.16532468]\n",
      "   [-0.55558993 -0.87994827]]]\n",
      "\n",
      "\n",
      " [[[ 0.80311509  0.93695209]\n",
      "   [ 0.15403238  0.41147223]]\n",
      "\n",
      "  [[ 1.35870502  1.81690036]\n",
      "   [ 1.91429495  2.69684864]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [0. 0.]\n",
      "analytic grad is \n",
      " [ 0.50875513 -0.24587434]\n",
      "numeric grad array is \n",
      " [ 0.50875513 -0.24587434]\n",
      "==========================================\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# First test - check the shape is right\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "\n",
    "# # Actually test the backward pass\n",
    "# # As usual, you'll need to copy gradient check code from the previous assignment\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_gradient(layer, X)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'W')\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Осталось реализовать дополнение нулями (padding).  \n",
    "Достаточно дополнить входной тензор нулями по сторонам. Не забудьте учесть это при обратном проходе!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  (2, 2, 2, 2)\n",
      "result shape is  (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "print(\"X shape \", X.shape)            \n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "result = layer.forward(X)\n",
    "print(\"result shape is \", result.shape)\n",
    "# Note this kind of layer produces the same dimensions as input\n",
    "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "# layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "# assert check_layer_gradient(layer, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### После следующего слоя вам уже будет все ни по чем - max pooling\n",
    "\n",
    "Max Pooling - это слой, реализующий операцию максимума для каждого канала отдельно в окресности из pool_size \"пикселей\".\n",
    "\n",
    "![Getting Started](max_pooling.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  (2, 2, 2, 2)\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 1.  0.]\n",
      "   [ 2.  1.]]\n",
      "\n",
      "  [[ 0. -1.]\n",
      "   [-1. -2.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.]\n",
      "   [ 1. -1.]]\n",
      "\n",
      "  [[-2.  2.]\n",
      "   [-1.  0.]]]]\n",
      "analytic grad is \n",
      " [[[[-1.00432271 -0.99819173]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[-1.37304255 -1.06774201]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]]\n",
      "numeric grad array is \n",
      " [[[[-1.00432271 -0.99819173]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[-1.37304255 -1.06774201]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "print(\"X shape \", X.shape) \n",
    "\n",
    "\n",
    "pool = MaxPoolingLayer(2, 2)\n",
    "result = pool.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "assert check_layer_gradient(pool, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is  (2, 4, 3, 3)\n",
      "transformed X shape is  (3, 3, 4, 2)\n",
      "[[13.  9.  3.]\n",
      " [ 2. 22.  2.]]\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 1, 0.0], [2.0, 1, 1.0], [9.0, 1, 1.0]],\n",
    "               [[0.0, 1,  -1.0], [-1.0, 1,  -2.0],[2.0, 1, 1.0]], \n",
    "               [[0.0, 1,  -1.0], [-5.0, 1,  -2.0],[2.0, 9, 1.0]],\n",
    "               [[0.0, 1,  3.0], [13.0, 1,  -2.0],[2.0, 1, 1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1, 1.0], [1.0, 1,  -1.0], [2.0, 1, 1.0]],\n",
    "               [[-2.0, 1,  2.0], [-1.0, 1, 0.0], [2.0, 1, 1.0]],\n",
    "               [[-2.0, 1,  2.0], [-1.0, 1, 0.0], [2.0, 1, 1.0]],\n",
    "               [[0.0, 1,  -1.0], [-1.0, 22,  -2.0],[2.0, 1, 1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# A = np.array([[[3,3], [2,2]], [[3,3,], [1,1]]])\n",
    "x_off= 1\n",
    "y_off = 1\n",
    "Y = X[:, x_off:2+x_off,  y_off:2 + y_off, :]\n",
    "print(\"X shape is \", X.shape)\n",
    "# print(\"Y shape is \", Y.shape)\n",
    "# print(X)\n",
    "# print(X.ndim)\n",
    "# print(\"Y is\\n\", Y)\n",
    "# print(\"A\\n\", A)\n",
    "print(\"transformed X shape is \", X.T.shape)\n",
    "\n",
    "b = [1000, 100, 30]\n",
    "# print(X + b)\n",
    "maxes = X.max(axis=(1, 2))\n",
    "# indices = X.argmax(axis=(1, 2))\n",
    "# indices = X.argmax(axis= (1,2))\n",
    "x, y = np.argwhere(maxes==maxes.max())[0]\n",
    "print(maxes)\n",
    "print(x, y)\n",
    "# print(maxes[ind[0], ind[1]])\n",
    "# print(maxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

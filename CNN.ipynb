{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Задание 3.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
    "\n",
    "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.  \n",
    "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
    "from model import ConvNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные\n",
    "\n",
    "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности `(num_samples, 32, 32, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):    \n",
    "    train_X = train_X.astype(float) / 255.0\n",
    "    test_X = test_X.astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_X, axis = 0)\n",
    "    train_X -= mean_image\n",
    "    test_X -= mean_image\n",
    "    \n",
    "    return train_X, test_X\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуем новые слои!\n",
    "Сначала основной новый слой - сверточный (Convolutional layer). Для начала мы реализуем его для только одного канала, а потом для нескольких.\n",
    "\n",
    "Сверточный слой выполняет операцию свертки (convolution) с весами для каждого канала, а потом складывает результаты. Возможно, поможет пересмотреть Лекцию 6 или внимательно прочитать http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Один из подходов к реализации сверточного слоя основан на том, что для конкретного \"пикселя\" выхода применение сверточного слоя эквивалентно обычному полносвязному.\n",
    "\n",
    "![Getting Started](conv_img.jpg)\n",
    "\n",
    "Рассмотрим один такой \"пиксель\":\n",
    "\n",
    "Он получает на вход  \n",
    "регион входа I размера `(batch_size, filter_size, filter_size, input_channels)`,\n",
    "\n",
    "применяет к нему веса W `(filter_size, filter_size, input_channels, output_channels` и выдает `(batch_size, output_channels)`.\n",
    "\n",
    "Если:  \n",
    "* вход преобразовать в I' `(batch_size, filter_size*filter_size*input_channels)`,  \n",
    "* веса в W' `(filter_size*filter_size*input_channels, output_channels)`,\n",
    "\n",
    "то выход \"пикселе\" будет эквивалентен полносвязному слою со входом I' и весами W'.  \n",
    "Осталось выполнить его в цикле для каждого пикселя :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2, 2, 2, 1)\n",
      "Shape of W (2, 2, 1, 1)\n",
      "Shape of X: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
    "\n",
    "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
    "# (batch_size, height, width, channels)\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0], [2.0]],\n",
    "               [[0.0], [-1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0], [1.0]],\n",
    "               [[-2.0], [-1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# Batch of 2 images of dimensions 2x2 with a single channel\n",
    "print(\"Shape of X:\",X.shape)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
    "print(\"Shape of W\", layer.W.value.shape)\n",
    "layer.W.value = np.zeros_like(layer.W.value)\n",
    "layer.W.value[0, 0, 0, 0] = 1.0\n",
    "layer.B.value = np.ones_like(layer.B.value)\n",
    "result = layer.forward(X)\n",
    "\n",
    "assert result.shape == (2, 1, 1, 1)\n",
    "assert np.all(result == X[:, :1, :1, :1] +1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
    "\n",
    "\n",
    "# Now let's implement multiple output channels\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "\n",
    "# And now multple input channels!\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь имплементируем обратный проход\n",
    "\n",
    "Возможно, это самое сложное место в курсе. Дальше будет лучше.\n",
    "\n",
    "Раз выполнение сверточного слоя эквивалентно полносвязному слою для каждого \"пикселя\" выхода, то общий обратный проход эквивалентен обратному проходу каждого из таких \"слоев\".  \n",
    "Градиенты от каждого из этих \"слоев\" в каждом пикселе надо сложить в соответствующие пиксели градиента по входу, а градиенты весов сложить все вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.W.grad\n",
      "  [[[[ 1.  1.]\n",
      "   [ 1.  1.]]\n",
      "\n",
      "  [[ 3.  3.]\n",
      "   [ 0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-2. -2.]\n",
      "   [ 1.  1.]]\n",
      "\n",
      "  [[-2. -2.]\n",
      "   [-2. -2.]]]]\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 1.  0.]\n",
      "   [ 2.  1.]]\n",
      "\n",
      "  [[ 0. -1.]\n",
      "   [-1. -2.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.]\n",
      "   [ 1. -1.]]\n",
      "\n",
      "  [[-2.  2.]\n",
      "   [-1.  0.]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "analytic grad is \n",
      " [[[[ 0.95391504 -0.52841742]\n",
      "   [ 0.34578707  0.65632938]]\n",
      "\n",
      "  [[ 0.14372389  0.86567082]\n",
      "   [ 0.08690502  1.00134383]]]\n",
      "\n",
      "\n",
      " [[[ 1.91996079 -0.63263871]\n",
      "   [ 0.53784188  0.91825745]]\n",
      "\n",
      "  [[ 0.20295892  2.10416283]\n",
      "   [-0.20497892  1.78365021]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265907  0.32706948]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83264241  0.32706294]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63160575  0.37776244]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.6315891   0.3777559 ]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29690723  1.03189486]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689058  1.03188832]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79893836 -0.05068969]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79895501 -0.05069623]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26318653 -0.75551507]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26320318 -0.75552161]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43055244  0.4284554 ]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43053579  0.42844886]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46423984 -0.70482211]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46425649 -0.70482865]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66529315 -0.65412915]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530981 -0.65413569]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83266706  0.32706999]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83263442  0.32706243]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63161374  0.37776295]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63158111  0.37775539]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29691522  1.03189537]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29688259  1.03188781]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79893037 -0.05068918]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.798963   -0.05069674]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26317854 -0.75551456]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26321117 -0.75552212]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43056043  0.42845591]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.4305278   0.42844835]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46423185 -0.7048216 ]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46426448 -0.70482916]\n",
      "   [-1.66530148 -0.65413242]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66528516 -0.65412864]]]]\n",
      "self.W.grad\n",
      "  [[[[ 0.83265074  0.32706621]\n",
      "   [ 1.63159743  0.37775917]]\n",
      "\n",
      "  [[ 3.29689891  1.03189159]\n",
      "   [-0.79894669 -0.05069296]]]\n",
      "\n",
      "\n",
      " [[[-3.26319486 -0.75551834]\n",
      "   [ 2.43054412  0.42845213]]\n",
      "\n",
      "  [[-2.46424817 -0.70482538]\n",
      "   [-1.66531779 -0.6541362 ]]]]\n",
      "numeric grad array is \n",
      " [[[[ 0.95391504 -0.52841742]\n",
      "   [ 0.34578707  0.65632938]]\n",
      "\n",
      "  [[ 0.14372389  0.86567082]\n",
      "   [ 0.08690502  1.00134383]]]\n",
      "\n",
      "\n",
      " [[[ 1.91996079 -0.63263871]\n",
      "   [ 0.53784188  0.91825745]]\n",
      "\n",
      "  [[ 0.20295892  2.10416283]\n",
      "   [-0.20497892  1.78365021]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 0.23986711  0.15895867]\n",
      "   [ 0.19286396 -1.15701728]]\n",
      "\n",
      "  [[ 0.77067305 -0.13043973]\n",
      "   [ 1.8219151  -0.07565047]]]\n",
      "\n",
      "\n",
      " [[[ 0.42091828  0.24660219]\n",
      "   [-0.62555704  0.99213683]]\n",
      "\n",
      "  [[ 1.90506364 -0.01477722]\n",
      "   [-0.30047879 -0.35502873]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "analytic grad is \n",
      " [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "numeric grad array is \n",
      " [[[[-1.89236189 -0.17781314]\n",
      "   [ 0.25099812  1.05475793]]\n",
      "\n",
      "  [[-3.53372567  0.69913164]\n",
      "   [-2.14336001 -1.23257107]]]\n",
      "\n",
      "\n",
      " [[[-0.50199623 -2.10951585]\n",
      "   [ 2.39435813  2.28732899]]\n",
      "\n",
      "  [[ 1.64136378 -0.87694478]\n",
      "   [ 3.78472379  0.35562629]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [0. 0.]\n",
      "self.W.grad\n",
      "  [[[[-1.13900819 -1.21440138]\n",
      "   [ 0.87096178 -0.87797062]]\n",
      "\n",
      "  [[-1.4070546  -3.30677338]\n",
      "   [-2.00996998 -0.33643077]]]\n",
      "\n",
      "\n",
      " [[[-1.74192356  1.75594123]\n",
      "   [ 2.88093176 -0.54153985]]\n",
      "\n",
      "  [[ 0.26804641  2.092372  ]\n",
      "   [ 2.27801639  2.42880277]]]]\n",
      "analytic grad is \n",
      " [-0.26804641 -2.092372  ]\n",
      "self.W.grad\n",
      "  [[[[-1.13900819 -1.21440138]\n",
      "   [ 0.87096178 -0.87797062]]\n",
      "\n",
      "  [[-1.4070546  -3.30677338]\n",
      "   [-2.00996998 -0.33643077]]]\n",
      "\n",
      "\n",
      " [[[-1.74192356  1.75594123]\n",
      "   [ 2.88093176 -0.54153985]]\n",
      "\n",
      "  [[ 0.26804641  2.092372  ]\n",
      "   [ 2.27801639  2.42880277]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.13900819 -1.21440138]\n",
      "   [ 0.87096178 -0.87797062]]\n",
      "\n",
      "  [[-1.4070546  -3.30677338]\n",
      "   [-2.00996998 -0.33643077]]]\n",
      "\n",
      "\n",
      " [[[-1.74192356  1.75594123]\n",
      "   [ 2.88093176 -0.54153985]]\n",
      "\n",
      "  [[ 0.26804641  2.092372  ]\n",
      "   [ 2.27801639  2.42880277]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.13900819 -1.21440138]\n",
      "   [ 0.87096178 -0.87797062]]\n",
      "\n",
      "  [[-1.4070546  -3.30677338]\n",
      "   [-2.00996998 -0.33643077]]]\n",
      "\n",
      "\n",
      " [[[-1.74192356  1.75594123]\n",
      "   [ 2.88093176 -0.54153985]]\n",
      "\n",
      "  [[ 0.26804641  2.092372  ]\n",
      "   [ 2.27801639  2.42880277]]]]\n",
      "self.W.grad\n",
      "  [[[[-1.13900819 -1.21440138]\n",
      "   [ 0.87096178 -0.87797062]]\n",
      "\n",
      "  [[-1.4070546  -3.30677338]\n",
      "   [-2.00996998 -0.33643077]]]\n",
      "\n",
      "\n",
      " [[[-1.74192356  1.75594123]\n",
      "   [ 2.88093176 -0.54153985]]\n",
      "\n",
      "  [[ 0.26804641  2.092372  ]\n",
      "   [ 2.27801639  2.42880277]]]]\n",
      "numeric grad array is \n",
      " [-0.26804641 -2.092372  ]\n",
      "==========================================\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# First test - check the shape is right\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "\n",
    "# # Actually test the backward pass\n",
    "# # As usual, you'll need to copy gradient check code from the previous assignment\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_gradient(layer, X)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'W')\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Осталось реализовать дополнение нулями (padding).  \n",
    "Достаточно дополнить входной тензор нулями по сторонам. Не забудьте учесть это при обратном проходе!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  (2, 2, 2, 2)\n",
      "result shape is  (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "print(\"X shape \", X.shape)            \n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "result = layer.forward(X)\n",
    "print(\"result shape is \", result.shape)\n",
    "# Note this kind of layer produces the same dimensions as input\n",
    "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "# layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "# assert check_layer_gradient(layer, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### После следующего слоя вам уже будет все ни по чем - max pooling\n",
    "\n",
    "Max Pooling - это слой, реализующий операцию максимума для каждого канала отдельно в окресности из pool_size \"пикселей\".\n",
    "\n",
    "![Getting Started](max_pooling.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  (2, 2, 2, 2)\n",
      "result is\n",
      " [[[[2. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 2.]]]]\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 1.  0.]\n",
      "   [ 2.  1.]]\n",
      "\n",
      "  [[ 0. -1.]\n",
      "   [-1. -2.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.]\n",
      "   [ 1. -1.]]\n",
      "\n",
      "  [[-2.  2.]\n",
      "   [-1.  0.]]]]\n",
      "analytic grad is \n",
      " [[[[ 0.          0.        ]\n",
      "   [-0.30374029 -0.10540882]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.        ]\n",
      "   [ 0.52376836  0.        ]]\n",
      "\n",
      "  [[ 0.          0.14297433]\n",
      "   [ 0.          0.        ]]]]\n",
      "numeric grad array is \n",
      " [[[[ 0.          0.        ]\n",
      "   [-0.30374029 -0.10540882]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.        ]\n",
      "   [ 0.52376836  0.        ]]\n",
      "\n",
      "  [[ 0.          0.14297433]\n",
      "   [ 0.          0.        ]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "print(\"X shape \", X.shape) \n",
    "\n",
    "\n",
    "pool = MaxPoolingLayer(2, 2)\n",
    "result = pool.forward(X)\n",
    "print(\"result is\\n\", result)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "assert check_layer_gradient(pool, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  (2, 4, 4, 2)\n",
      "X[0]\n",
      " [[[ 1.  2. -1. -1.]\n",
      "  [ 0. -1. -1. -1.]\n",
      "  [-2. -1. -1. -1.]\n",
      "  [-2. -1. -1. -1.]]\n",
      "\n",
      " [[ 0. -1.  1. -1.]\n",
      "  [-2. -1. -1. -1.]\n",
      "  [-2. -1. -1. -1.]\n",
      "  [-2. -1. -1. -1.]]]\n",
      "result is\n",
      " [[[[ 2.  1.]\n",
      "   [-1. -2.]]\n",
      "\n",
      "  [[-1.  2.]\n",
      "   [-1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  2.]\n",
      "   [ 1.  0.]]\n",
      "\n",
      "  [[-1.  2.]\n",
      "   [-1.  0.]]]]\n",
      "fragment x \n",
      " [[ 1.  2.]\n",
      " [ 0. -1.]]\n",
      "ind is \n",
      " [0 1]\n",
      "fragment x \n",
      " [[-1. -1.]\n",
      " [-1. -1.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[-2. -1.]\n",
      " [-2. -1.]]\n",
      "ind is \n",
      " [0 1]\n",
      "fragment x \n",
      " [[-1. -1.]\n",
      " [-1. -1.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 0.  1.]\n",
      " [-1. -2.]]\n",
      "ind is \n",
      " [0 1]\n",
      "fragment x \n",
      " [[-2. -2.]\n",
      " [-2. -2.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 2. -2.]\n",
      " [ 2. -2.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 0. -2.]\n",
      " [ 0. -2.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 0. -1.]\n",
      " [-2. -1.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 1. -1.]\n",
      " [-1. -1.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[-2. -1.]\n",
      " [-2. -1.]]\n",
      "ind is \n",
      " [0 1]\n",
      "fragment x \n",
      " [[-1. -1.]\n",
      " [-1. -1.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 1. -2.]\n",
      " [ 2. -2.]]\n",
      "ind is \n",
      " [1 0]\n",
      "fragment x \n",
      " [[-1. -2.]\n",
      " [ 0. -2.]]\n",
      "ind is \n",
      " [1 0]\n",
      "fragment x \n",
      " [[ 2. -2.]\n",
      " [ 2. -2.]]\n",
      "ind is \n",
      " [0 0]\n",
      "fragment x \n",
      " [[ 0. -2.]\n",
      " [ 0. -2.]]\n",
      "ind is \n",
      " [0 0]\n",
      "d input[0] is \n",
      " [[[ 0.  2. -1.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0. -1. -1.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0. -1. -1.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0], [-1.0, -2.0], [-1.0, -2.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0], [-1.0, -2.0],[-1.0, -2.0]],\n",
    "               [[-2.0, 2.0], [-1.0, -2.0], [-1.0, 0.0],[-1.0, -2.0]],\n",
    "               [[-2.0, 2.0], [-1.0, -2.0], [-1.0, 0.0],[-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [-1.0, -2.0], [1.0, -1.0],[-1.0, -2.0]],\n",
    "               [[-2.0, 2.0], [-1.0, -2.0], [-1.0, 0.0], [-1.0, -2.0]],\n",
    "               [[-2.0, 2.0], [-1.0, -2.0], [-1.0, 0.0], [-1.0, -2.0]],\n",
    "               [[-2.0, 2.0], [-1.0, -2.0], [-1.0, 0.0],[-1.0, -2.0]]\n",
    "              ]\n",
    "             ])\n",
    "print(\"X shape \", X.shape) \n",
    "print(\"X[0]\\n\", X[:,:,:,0])\n",
    "# print(\"X[1]\\n\", X[:,:,:,1])\n",
    "\n",
    "\n",
    "pool = MaxPoolingLayer(2, 2)\n",
    "result = pool.forward(X)\n",
    "print(\"result is\\n\", result)\n",
    "d_input = pool.backward(result)\n",
    "# assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "# assert check_layer_gradient(pool, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на закуску - слой, преобразующий четырехмерные тензоры в двумерные.\n",
    "\n",
    "Этот слой понадобится нам, чтобы в конце сети перейти от сверточных слоев к полносвязным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18135/3150306947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflattener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlattener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mcheck_layer_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flattener = Flattener()\n",
    "result = flattener.forward(X)\n",
    "assert result.shape == (2,8)\n",
    "\n",
    "assert check_layer_gradient(flattener, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь есть все кирпичики, создаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 0.55727908  1.54882947]\n",
      "   [-1.70367018  0.14685858]\n",
      "   [ 1.57739465  0.77912164]]\n",
      "\n",
      "  [[ 2.16594136 -0.49624807]\n",
      "   [ 1.08521047  0.71844019]\n",
      "   [ 0.05058829 -1.01231956]]\n",
      "\n",
      "  [[ 0.22373236  1.9337601 ]\n",
      "   [ 1.24988081  0.48841608]\n",
      "   [-0.49391724 -1.40751252]]]\n",
      "\n",
      "\n",
      " [[[-0.19902985 -0.90898711]\n",
      "   [-0.35590979  1.10262794]\n",
      "   [ 1.22524106  1.08717756]]\n",
      "\n",
      "  [[ 0.54415423 -0.52979635]\n",
      "   [ 0.43899802 -1.72670806]\n",
      "   [ 1.10404606 -1.09934292]]\n",
      "\n",
      "  [[ 1.33413655 -0.63354464]\n",
      "   [ 2.23311422 -0.26385797]\n",
      "   [-0.1156972   0.76240023]]]\n",
      "\n",
      "\n",
      " [[[-1.34186612  0.21859976]\n",
      "   [-1.00528307  0.67685075]\n",
      "   [ 0.49975637  0.2243302 ]]\n",
      "\n",
      "  [[ 1.23618233  0.14349703]\n",
      "   [-2.19476646 -0.7532163 ]\n",
      "   [-0.95958156  0.66338589]]\n",
      "\n",
      "  [[-0.20235996 -0.64302906]\n",
      "   [-0.81345253 -0.34161743]\n",
      "   [ 0.42184006  0.88950668]]]]\n",
      "analytic grad is \n",
      " [[[[-5.65171082e-04 -3.97847271e-04]\n",
      "   [-5.09973165e-04 -8.05150719e-04]\n",
      "   [-3.88429285e-04 -1.63802219e-03]]\n",
      "\n",
      "  [[-1.21961138e-03  2.94948798e-04]\n",
      "   [-1.18283146e-03 -7.62000086e-05]\n",
      "   [-9.33950427e-04 -8.76299513e-04]]\n",
      "\n",
      "  [[-1.73174907e-03  3.61098960e-04]\n",
      "   [-1.65367956e-03  6.32191625e-05]\n",
      "   [-1.37831306e-03 -6.52756161e-04]]]\n",
      "\n",
      "\n",
      " [[[ 2.08851566e-04 -1.74805694e-03]\n",
      "   [ 1.21706002e-04 -1.76340591e-03]\n",
      "   [ 1.90154704e-04 -1.68836248e-03]]\n",
      "\n",
      "  [[-6.59848465e-04 -1.13603400e-03]\n",
      "   [-7.14235996e-04 -1.12511007e-03]\n",
      "   [-5.82992651e-04 -1.08419713e-03]]\n",
      "\n",
      "  [[-1.25023711e-03 -1.00896959e-03]\n",
      "   [-1.29050622e-03 -9.91018309e-04]\n",
      "   [-1.16641511e-03 -9.23051864e-04]]]\n",
      "\n",
      "\n",
      " [[[ 1.04252265e-03 -1.76269154e-03]\n",
      "   [ 9.16094668e-04 -1.78055707e-03]\n",
      "   [ 8.99305220e-04 -1.71566862e-03]]\n",
      "\n",
      "  [[ 1.86209759e-04 -1.40978896e-03]\n",
      "   [ 1.16302487e-05 -1.35000580e-03]\n",
      "   [ 4.14523819e-05 -1.31103316e-03]]\n",
      "\n",
      "  [[-4.10165563e-04 -9.85644579e-04]\n",
      "   [-5.74047775e-04 -9.53784212e-04]\n",
      "   [-5.06405566e-04 -9.40302340e-04]]]]\n",
      "numeric grad array is \n",
      " [[[[-5.65171110e-04 -3.97847266e-04]\n",
      "   [-5.09973175e-04 -8.05150702e-04]\n",
      "   [-3.88429289e-04 -1.63802225e-03]]\n",
      "\n",
      "  [[-1.21961135e-03  2.94948777e-04]\n",
      "   [-1.18283148e-03 -7.61999797e-05]\n",
      "   [-9.33950428e-04 -8.76299522e-04]]\n",
      "\n",
      "  [[-1.73174906e-03  3.61098973e-04]\n",
      "   [-1.65367959e-03  6.32191632e-05]\n",
      "   [-1.37831306e-03 -6.52756160e-04]]]\n",
      "\n",
      "\n",
      " [[[ 2.08851514e-04 -1.74805694e-03]\n",
      "   [ 1.21706023e-04 -1.76340587e-03]\n",
      "   [ 1.90154648e-04 -1.68836247e-03]]\n",
      "\n",
      "  [[-6.59848443e-04 -1.13603402e-03]\n",
      "   [-7.14236004e-04 -1.12511005e-03]\n",
      "   [-5.82992632e-04 -1.08419713e-03]]\n",
      "\n",
      "  [[-1.25023711e-03 -1.00896953e-03]\n",
      "   [-1.29050624e-03 -9.91018334e-04]\n",
      "   [-1.16641514e-03 -9.23051902e-04]]]\n",
      "\n",
      "\n",
      " [[[ 1.04252269e-03 -1.76269155e-03]\n",
      "   [ 9.16094667e-04 -1.78055708e-03]\n",
      "   [ 8.99305252e-04 -1.71566863e-03]]\n",
      "\n",
      "  [[ 1.86209759e-04 -1.40978895e-03]\n",
      "   [ 1.16302523e-05 -1.35000580e-03]\n",
      "   [ 4.14524415e-05 -1.31103315e-03]]\n",
      "\n",
      "  [[-4.10165546e-04 -9.85644588e-04]\n",
      "   [-5.74047743e-04 -9.53784207e-04]\n",
      "   [-5.06405495e-04 -9.40302369e-04]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [0. 0.]\n",
      "analytic grad is \n",
      " [-0.00087713 -0.00626793]\n",
      "numeric grad array is \n",
      " [-0.00087713 -0.00626793]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[[[ 0.0375063  -0.44287886]\n",
      "   [ 0.03925138 -1.21109962]]\n",
      "\n",
      "  [[-0.4579228   1.42861296]\n",
      "   [ 1.07220443  2.23646335]]\n",
      "\n",
      "  [[-0.73320186  2.60024269]\n",
      "   [-0.50685124 -0.65315241]]]\n",
      "\n",
      "\n",
      " [[[ 0.29699761  0.49130365]\n",
      "   [ 0.19424043 -0.07757472]]\n",
      "\n",
      "  [[ 2.06182637 -1.19794351]\n",
      "   [-1.09654928  0.21283793]]\n",
      "\n",
      "  [[-0.09730597  0.05091345]\n",
      "   [ 2.31788152  1.67167912]]]\n",
      "\n",
      "\n",
      " [[[ 0.64326773 -0.76586548]\n",
      "   [ 0.25510342 -1.74182902]]\n",
      "\n",
      "  [[-0.84884284  0.74974972]\n",
      "   [-0.93947426 -0.61405923]]\n",
      "\n",
      "  [[ 0.22421538 -2.93746374]\n",
      "   [ 0.21262907  0.31352128]]]]\n",
      "analytic grad is \n",
      " [[[[-0.00542823 -0.00382433]\n",
      "   [-0.00074868 -0.00110434]]\n",
      "\n",
      "  [[-0.00632996 -0.00541921]\n",
      "   [-0.00124948 -0.00164711]]\n",
      "\n",
      "  [[-0.00206155 -0.00691446]\n",
      "   [-0.0002077  -0.00173865]]]\n",
      "\n",
      "\n",
      " [[[ 0.00198851 -0.00382755]\n",
      "   [ 0.00174186 -0.00120831]]\n",
      "\n",
      "  [[ 0.00075639 -0.00333017]\n",
      "   [ 0.00132805 -0.00166928]]\n",
      "\n",
      "  [[ 0.00014673 -0.00447265]\n",
      "   [ 0.00277376 -0.00154495]]]\n",
      "\n",
      "\n",
      " [[[ 0.00629338 -0.00137897]\n",
      "   [ 0.00228238 -0.00039879]]\n",
      "\n",
      "  [[ 0.00736319 -0.00331924]\n",
      "   [ 0.00177919 -0.00100118]]\n",
      "\n",
      "  [[ 0.00483341 -0.00190554]\n",
      "   [ 0.00210252 -0.00159914]]]]\n",
      "numeric grad array is \n",
      " [[[[-0.00542823 -0.00382433]\n",
      "   [-0.00074868 -0.00110434]]\n",
      "\n",
      "  [[-0.00632996 -0.00541921]\n",
      "   [-0.00124948 -0.00164711]]\n",
      "\n",
      "  [[-0.00206155 -0.00691446]\n",
      "   [-0.0002077  -0.00173865]]]\n",
      "\n",
      "\n",
      " [[[ 0.00198851 -0.00382755]\n",
      "   [ 0.00174186 -0.00120831]]\n",
      "\n",
      "  [[ 0.00075639 -0.00333017]\n",
      "   [ 0.00132805 -0.00166928]]\n",
      "\n",
      "  [[ 0.00014673 -0.00447265]\n",
      "   [ 0.00277376 -0.00154495]]]\n",
      "\n",
      "\n",
      " [[[ 0.00629338 -0.00137897]\n",
      "   [ 0.00228238 -0.00039879]]\n",
      "\n",
      "  [[ 0.00736319 -0.00331924]\n",
      "   [ 0.00177919 -0.00100118]]\n",
      "\n",
      "  [[ 0.00483341 -0.00190554]\n",
      "   [ 0.00210252 -0.00159914]]]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [0. 0.]\n",
      "analytic grad is \n",
      " [ 0.00121374 -0.00401978]\n",
      "numeric grad array is \n",
      " [ 0.00121374 -0.00401978]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "Checking gradient for W3\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[ 5.67825959e-04  1.68266020e-03 -5.16286546e-04 -2.05854822e-04\n",
      "  -7.85945337e-04 -6.20884793e-04 -7.22304401e-04 -7.19337204e-04\n",
      "  -1.96086859e-03 -1.14170846e-03]\n",
      " [ 7.95876657e-04 -3.40183359e-04 -4.92150182e-04 -4.34961893e-04\n",
      "   3.13791302e-04 -1.32716404e-03  9.10619885e-04 -2.07948613e-03\n",
      "   1.01778736e-03  4.26674560e-04]\n",
      " [-2.05907986e-03  8.65664883e-05  3.99968729e-04 -1.19417351e-03\n",
      "  -6.55964865e-05 -1.51673519e-03  8.67876687e-04  7.04035505e-04\n",
      "  -1.41630124e-05 -2.55133733e-03]\n",
      " [-5.91046200e-05 -1.78263299e-04 -6.72131117e-04 -1.45773607e-03\n",
      "  -8.41527384e-04 -4.92428098e-04 -1.05459128e-04  6.58706539e-04\n",
      "   6.27759403e-04  2.02705778e-04]\n",
      " [-1.02861646e-03  1.99859496e-04  6.57178835e-04  6.90478221e-04\n",
      "   9.58951625e-04 -2.32206721e-03 -1.44315361e-03 -3.93105543e-04\n",
      "   7.83826917e-04  8.43107950e-04]\n",
      " [-6.27495349e-04  2.08020533e-03 -1.86234975e-03 -3.25187179e-04\n",
      "   6.91859913e-04 -4.64467191e-04 -9.38916509e-04  1.21233882e-03\n",
      "  -1.30560536e-04  2.12309006e-04]\n",
      " [ 1.20128792e-03 -7.99431318e-04  2.02868380e-04 -4.15315175e-04\n",
      "  -1.19837839e-03  1.06813494e-03  5.38984644e-04  2.84617435e-04\n",
      "   8.25485773e-05  1.40620074e-03]\n",
      " [-2.58035925e-03 -2.87997583e-04 -1.45415099e-03  2.42414929e-04\n",
      "   1.22379834e-03 -8.51228323e-04  1.52658725e-03  3.69450988e-04\n",
      "   7.81736271e-04  8.07586233e-04]]\n",
      "analytic grad is \n",
      " [[  0.93910306   0.98822435   0.93539057   0.94965796   0.97594599\n",
      "    0.92530203   0.97555866   0.96735305   0.97612686  -8.63266253]\n",
      " [  1.13796146   1.19708999   1.13346512   1.1506502    1.18229384\n",
      "    1.12132705   1.18178101   1.17195655   1.18250998 -10.45903519]\n",
      " [  0.86234277   0.9088025    0.85892588   0.87238227   0.89724566\n",
      "    0.84936423   0.89703923   0.88909684   0.89742215  -7.93262152]\n",
      " [  0.60566311   0.63645248   0.60327394   0.61224177   0.62871936\n",
      "    0.59696341   0.62837134   0.6233474    0.62882916  -5.56386198]\n",
      " [  0.71499982   0.75021072   0.71218594   0.72247439   0.74131849\n",
      "    0.70498625   0.74078231   0.73519364   0.74143938  -6.56359094]\n",
      " [  1.25465468   1.31615214   1.24971867   1.26769653   1.30060869\n",
      "    1.23714855   1.29963593   1.28991622   1.30081859 -11.51635001]\n",
      " [  0.756998     0.79766562   0.75399919   0.76578115   0.78754486\n",
      "    0.74563124   0.7873508    0.78041375   0.7876989   -6.96308351]\n",
      " [  1.14919492   1.21293945   1.14463081   1.16304367   1.19715684\n",
      "    1.13148595   1.19708355   1.18594818   1.19740611 -10.57888947]]\n",
      "numeric grad array is \n",
      " [[  0.93910306   0.98822435   0.93539057   0.94965796   0.97594599\n",
      "    0.92530203   0.97555866   0.96735305   0.97612686  -8.63266253]\n",
      " [  1.13796146   1.19708999   1.13346512   1.1506502    1.18229384\n",
      "    1.12132705   1.18178101   1.17195655   1.18250998 -10.45903519]\n",
      " [  0.86234277   0.9088025    0.85892588   0.87238227   0.89724566\n",
      "    0.84936423   0.89703923   0.88909684   0.89742215  -7.93262152]\n",
      " [  0.60566311   0.63645248   0.60327394   0.61224177   0.62871936\n",
      "    0.59696341   0.62837134   0.6233474    0.62882916  -5.56386198]\n",
      " [  0.71499982   0.75021072   0.71218594   0.72247439   0.74131849\n",
      "    0.70498625   0.74078231   0.73519364   0.74143938  -6.56359094]\n",
      " [  1.25465469   1.31615214   1.24971868   1.26769653   1.30060869\n",
      "    1.23714855   1.29963593   1.28991622   1.30081859 -11.51635001]\n",
      " [  0.756998     0.79766562   0.75399919   0.76578115   0.78754486\n",
      "    0.74563124   0.7873508    0.78041375   0.7876989   -6.96308351]\n",
      " [  1.14919492   1.21293946   1.14463081   1.16304367   1.19715684\n",
      "    1.13148595   1.19708355   1.18594818   1.19740611 -10.57888947]]\n",
      "==========================================\n",
      "Gradient check passed!\n",
      "Checking gradient for B3\n",
      "CHECK GRADIENT\n",
      "x is \n",
      " [[ 3.95242811e-04 -9.36288495e-04 -7.24719706e-04 -3.28013293e-05\n",
      "  -4.71613255e-04  5.63768676e-04 -2.26792732e-03  3.42653988e-04\n",
      "  -9.79672400e-05 -2.40244614e-04]]\n",
      "analytic grad is \n",
      " [[ 0.197229    0.204067    0.19646947  0.19855311  0.20221327  0.19511582\n",
      "   0.2017484   0.20107223  0.20222452 -1.79869283]]\n",
      "numeric grad array is \n",
      " [[ 0.197229    0.204067    0.19646947  0.19855311  0.20221327  0.19511582\n",
      "   0.2017484   0.20107223  0.20222452 -1.79869283]]\n",
      "==========================================\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement missed functions function for ConvNet model\n",
    "\n",
    "# No need to use L2 regularization\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизатор и код для тренировки\n",
    "\n",
    "Должен заработать с кодом из прошлого задания без изменений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is\n",
      " (16, 32, 32, 3)\n",
      "y shape is\n",
      " (16,)\n",
      "Epoch: 1, Loss: 36.847646, Train accuracy: 0.000000, val accuracy: 0.062500\n",
      "Epoch: 2, Loss: 36.838067, Train accuracy: 0.000000, val accuracy: 0.000000\n",
      "Epoch: 3, Loss: 36.828504, Train accuracy: 0.125000, val accuracy: 0.062500\n",
      "Epoch: 4, Loss: 36.818956, Train accuracy: 0.187500, val accuracy: 0.125000\n",
      "Epoch: 5, Loss: 36.809424, Train accuracy: 0.187500, val accuracy: 0.125000\n",
      "Epoch: 6, Loss: 36.799906, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 7, Loss: 36.790404, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 8, Loss: 36.780917, Train accuracy: 0.250000, val accuracy: 0.187500\n",
      "Epoch: 9, Loss: 36.771445, Train accuracy: 0.250000, val accuracy: 0.187500\n",
      "Epoch: 10, Loss: 36.761987, Train accuracy: 0.250000, val accuracy: 0.187500\n",
      "Epoch: 11, Loss: 36.752545, Train accuracy: 0.250000, val accuracy: 0.187500\n",
      "Epoch: 12, Loss: 36.743117, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 13, Loss: 36.733704, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 14, Loss: 36.724305, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 15, Loss: 36.714922, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 16, Loss: 36.705552, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 17, Loss: 36.696197, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 18, Loss: 36.686856, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 19, Loss: 36.677530, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Epoch: 20, Loss: 36.668218, Train accuracy: 0.250000, val accuracy: 0.125000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e886273d0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
    "trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "plt.plot(loss_history)\n",
    "# plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Последнее упражнение\n",
    "\n",
    "В качестве последнего упражнения мы доведем точность на тренировочном наборе данных до 100% на небольшом наборе данных.    \n",
    "Сверточные сети требуют большого количества вычислений и аккуратной эффективной реализации, поэтому настоящие модели мы будем тренировать уже на PyTorch в следующем задании.\n",
    "\n",
    "### Итак, оверфитим маленький набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is\n",
      " (128, 32, 32, 3)\n",
      "y shape is\n",
      " (128,)\n",
      "Epoch: 1, Loss: 2.286327, Train accuracy: 0.203125, val accuracy: 0.250000\n",
      "Epoch: 2, Loss: 2.114996, Train accuracy: 0.250000, val accuracy: 0.257812\n",
      "Epoch: 3, Loss: 1.919792, Train accuracy: 0.437500, val accuracy: 0.195312\n",
      "Epoch: 4, Loss: 1.802303, Train accuracy: 0.492188, val accuracy: 0.179688\n",
      "Epoch: 5, Loss: 1.597986, Train accuracy: 0.554688, val accuracy: 0.148438\n",
      "Epoch: 6, Loss: 1.383043, Train accuracy: 0.609375, val accuracy: 0.195312\n",
      "Epoch: 7, Loss: 1.137242, Train accuracy: 0.609375, val accuracy: 0.187500\n",
      "Epoch: 8, Loss: 1.023992, Train accuracy: 0.679688, val accuracy: 0.148438\n",
      "Epoch: 9, Loss: 0.848358, Train accuracy: 0.671875, val accuracy: 0.156250\n",
      "Epoch: 10, Loss: 0.848540, Train accuracy: 0.718750, val accuracy: 0.156250\n",
      "Epoch: 11, Loss: 0.797963, Train accuracy: 0.773438, val accuracy: 0.171875\n",
      "Epoch: 12, Loss: 0.580396, Train accuracy: 0.781250, val accuracy: 0.171875\n",
      "Epoch: 13, Loss: 0.692052, Train accuracy: 0.781250, val accuracy: 0.156250\n",
      "Epoch: 14, Loss: 0.517565, Train accuracy: 0.820312, val accuracy: 0.148438\n",
      "Epoch: 15, Loss: 0.516003, Train accuracy: 0.851562, val accuracy: 0.156250\n",
      "Epoch: 16, Loss: 0.559163, Train accuracy: 0.851562, val accuracy: 0.148438\n",
      "Epoch: 17, Loss: 0.430017, Train accuracy: 0.867188, val accuracy: 0.148438\n",
      "Epoch: 18, Loss: 0.298087, Train accuracy: 0.882812, val accuracy: 0.148438\n",
      "Epoch: 19, Loss: 0.390368, Train accuracy: 0.898438, val accuracy: 0.140625\n",
      "Epoch: 20, Loss: 0.263325, Train accuracy: 0.921875, val accuracy: 0.140625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18135/859239442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMomentumSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/SimonSays/Mashine-Learning-Examples/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 loss = self.model.compute_loss_and_gradients(\n\u001b[0m\u001b[1;32m    116\u001b[0m                     batch_X, batch_y)\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SimonSays/Mashine-Learning-Examples/model.py\u001b[0m in \u001b[0;36mcompute_loss_and_gradients\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0md_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# print(\"d_pool1 \\n \", d_pool1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0md_relu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SimonSays/Mashine-Learning-Examples/layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_out)\u001b[0m\n\u001b[1;32m    444\u001b[0m                         \u001b[0;31m# print(\"ind is \\n\", ind)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         d_input[batch, s_y + ind[0], s_x+ind[1],\n\u001b[0;32m--> 446\u001b[0;31m                                 c] = d_out[batch, y, x, c]\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# print(\"d input[0] is \\n\", d_input[:,:,:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_size = 128\n",
    "np.random.seed(7777)\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=8, conv2_channels=2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
    "# Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, num_epochs=50, batch_size=64, learning_rate_decay=0.99)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net train set accuracy: 1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj60lEQVR4nO3dd3xW5f3/8deVPckgg0ASwkoA2YStiDjBVevGgWjF2ao/W2f7/fot1W9tq3XWFhkKUhwIDlx1UEFlmMg0jLBCwsiAJASyk+v3R6JfikACuZOT+77fz8cjD3Pf57rv8zk99P04uc51rstYaxEREffn43QBIiLiGgp0EREPoUAXEfEQCnQREQ+hQBcR8RB+Tu04JibGpqSkOLV7ERG3lJmZWWStjT3WNscCPSUlhYyMDKd2LyLilowxOcfbpi4XEREPoUAXEfEQCnQREQ+hQBcR8RAKdBERD6FAFxHxEAp0EREP4XaBviW/jGmLs6isqXO6FBGRdsXtAj2vuJyZX+0gM6fY6VJERNoVtwv0kd074u9rWLql0OlSRETaFbcL9JAAP9K7RrM0u8jpUkRE2hW3C3SAM1Jj2Lj3IAVllU6XIiLSbrhloI/t1TDR2NdbdZUuIvIDtwz0vgkd6BgawNItCnQRkR+4ZaD7+BhO7xXDsuwi6uut0+WIiLQLbhnoAGf0iqXoUBWb9pU5XYqISLvgxoEeA8CybA1fFBEBNw70+A5BpMWHs1SBLiICuHGgA4xNjeHbHcVUVGsaABERtw70M1PjqK6rZ8nmAqdLERFxnFsH+qgeHekSGcy8lcddM1VExGu4daD7+hgmjUjm66372VpwyOlyREQc5daBDnD1sCT8fY2u0kXE67l9oMeEBTKhXwILMvMor651uhwREce4faAD3DCqK2WVtby3Zg8A1lo27yujTk+RiogX8WuqgTEmCZgDxAMWmG6tffaoNtcBDwIGKAPusNaudX25x5beNYrencKZszyHQH8fpi/dwca9B/nF6d347UV926oMERFHNecKvRa431rbFxgJ3GWMOToldwBnWmv7A9OA6a4t88SMMVw/sitZew9y3xtrqa2r58zUWGZ+vYPl2/a3ZSkiIo5p8grdWrsX2Nv4e5kxZiPQBcg6os03R3xkBZDo4jqbdPmQRHKLyxnZvSPjUmOpqKlj4rPL+PVba/n43jMID/Jv65JERNrUSfWhG2NSgMHAyhM0uwX4qAU1nZLgAF8entCHs9LiMMYQEuDHU1cNYm9pBdMWZzX9BSIibq7ZgW6MCQPeBu611h48TpuzaAj0B4+zfaoxJsMYk1FY2PpzsAztGsUd43rwZkYeSzbpaVIR8WzNCnRjjD8NYT7PWrvwOG0GADOAS621x+y4ttZOt9amW2vTY2NjT7Xmk3LP2an0iA1l2uIsaurq22SfIiJOaDLQjTEGmAlstNY+fZw2ycBC4AZr7RbXltgyAX4+PDKxD9uLDjN/1S6nyxERaTXNuUIfA9wAjDfGrGn8mWiMud0Yc3tjm/8COgJ/a9ye0VoFn4rxveMY3aMjz3yWzcHKGqfLERFpFcZaZx6+SU9PtxkZbZf7G3aXcvELX3Hb2B48NKF3m+1XRMSVjDGZ1tr0Y23ziCdFm6NflwguG9yFWV/vIK+43OlyRERczmsCHeDX56UB8PcvtzlciYiI63lVoHeODObC/gm8u3qPVjkSEY/jVYEOcFV6EmVVtXz8/V6nSxERcSmvC/QR3aJJjg7hzW/znC5FRMSlvC7QfXwMV6Unsnz7fnL2H3a6HBERl/G6QAe4fGgiPgYWZOoqXUQ8h1cGekJEMGNTY1mQmadFMETEY3hloANcnZ7E3tJKlmW3/iRhIiJtwWsD/ew+8cSEBTBtcRaFZVVOlyMi0mJeG+gBfj68MGkIe0oqmfTyCooOKdRFxL15baADjOzekVk3DSO3uFyhLiJuz6sDHWBUj4ZQ33WgnDtey6ReN0lFxE15faADjO4Rw7RL+/HtzmL+qTnTRcRNKdAbXTE0kdN7xvDHjzaxt7TC6XJERE6aAr2RMYYnLutPbX09v3tnA07NEy8icqoU6EdI7hjC/eem8dnGAj5Yr8m7RMS9KNCPMmVMCv27RPDYe99TUl7tdDkiIs2mQD+Kn68PT14+gJLyGv7wwUanyxERaTYF+jH07dyB287szoLMPJZu0dQAIuIeFOjH8cvxvegeG8oji9ZzuKrW6XJERJqkQD+OIH9fnrx8AHnFFTz96RanyxERaZIC/QSGpURzzbAk5i7P0QReItLuKdCbMHVsd6rr6pm3MsfpUkRETkiB3oTusWGM7x3HaytyqKypc7ocEZHjUqA3wy2nd6PoUDXvr93jdCkiIselQG+G0T060rtTODO/2qEpAUSk3VKgN4MxhpvHdGPTvjKWb9/vdDkiIsekQG+mSwZ1pmNoAH9bso2aunqnyxER+QkFejMF+fty9/iefLW1iOteXkn+wUqnSxIR+Q8K9JMwZUw3nr1mEOt3l3Lhc8v4ZmuR0yWJiPyoyUA3xiQZY5YYY7KMMd8bY+45RhtjjHnOGLPVGLPOGDOkdcp13qWDuvDe3WOICPbn+pkrefazbOq0bJ2ItAPNuUKvBe631vYFRgJ3GWP6HtVmAtCr8Wcq8JJLq2xnesWH897dp3PpoC789bMtTJ61Sk+Siojjmgx0a+1ea+13jb+XARuBLkc1uxSYYxusACKNMQkur7YdCQ304+mrBvLk5f35ducBLnp+GTuKDjtdloh4sZPqQzfGpACDgZVHbeoC5B7xOo+fhj7GmKnGmAxjTEZhoftPS2uM4ephySy6cww1dZbrZ6xkX6luloqIM5od6MaYMOBt4F5r7cFT2Zm1drq1Nt1amx4bG3sqX9Eu9e3cgVenDKe0oobrZ67kwGGtdCQiba9ZgW6M8achzOdZaxceo8luIOmI14mN73mN/okRzJicTu6BcibPWkXOfnW/iEjbas4oFwPMBDZaa58+TrP3gBsbR7uMBEqttV63yvLI7h156fohbCs8xLlPL+XPn2yivFqLY4hI2zBNzU1ijDkdWAasB354RPIRIBnAWvv3xtB/AbgAKAemWGszTvS96enpNiPjhE3cVv7BSv740SYWrd5NQkQQ029Ip39ihNNliYgHMMZkWmvTj7nNqcmmPDnQf5Cx8wD3vL6G0ooaXr4xnVE9Ojpdkoi4uRMFup4UbUXpKdEsuGMUnSKCmDx7FZ9m5Ttdkoh4MAV6K0uICObN20bRp1M4t7+WyeJ1mlNdRFqHAr0NRIcGMO/WkQxJjuTe19fwr+/3OV2SiHggBXobCQv0Y9ZNw+jXJYK7/vkdSzYVOF2SiHgYBXobCg/y59Wbh5PWKZzbXsvkM/Wpi4gLKdDbWESwP3NvHkHvTuHcOjeDGcu2a1k7EXEJBboDokIDeGPqKM7v24k/fLCRR9/ZoFWQRKTFFOgOCQ7w5W/XDeGOcT3458pd3D43k8qaOqfLEhE3pkB3kI+P4cELejPtZ/34YnMBU2Z/y6EqTRUgIqdGgd4O3DCyK09fNZBVOw9w/YyVlJRrtkYROXkK9HbissGJvHTdELL2HGTqnEyqa9WnLiInR4Hejpx3Wif+fOUAVu08wH+9u0GjX0TkpPg5XYD8p0sHdWFLfhkvLtlGWqdwpozp5nRJIuImdIXeDt1/bhrn9o1n2uIslmW7/1J9ItI2FOjtkI+P4ZmrB9ErLpxfzV/N7pIKp0sSETegQG+nQgP9eOn6IdTUWe6a951ukopIkxTo7Vj32DD+dMUA1uSW8MSHG50uR0TaOd0Ubecm9k/gltO7MfOrHfgYw8CkCLrFhJIaH06Qv6/T5YlIO6JAdwMPTehNzv7DzP5mBz+MZAz292VcWiwX9OtEYlQw2fmH2JJ/iKgQf24d211hL+KFtKaoG6msqSP3QDnbCg/z9dYiPvl+HwVlVT9uD/L3obKmnt6dwnn2msGkdQp3sFoRaQ1aJNpD1ddbVueWUFJeTa+4cBKjgvlySyG/WbCWg5W1PDyhN5NHpeDjY5wuVURcRIHuZYoOVfHAgnV8samAMT078ucrBtI5MtjpskTEBU4U6Brl4oFiwgKZOTmdJy7rz+pdJZz/zFLe/DZXc66LeDhdoXu4nP2Huf/NtWTkFBMTFsgVQxMZ3zuOzfllfJdTzJ6SCm4Y1ZUL+ydgjLpmRNo7dbl4ubp6y5dbCpi/KpcvNhVQV99wzmPDAwkN8GXn/nIGJ0fy6MQ+pKdEO1ytiJyIAl1+lH+wkjW5JfRN6EBiVDD1Ft7+Lo+n/rWZ/INV/Gp8T+47N1VX6yLtlAJdmlReXctj733Pmxl5XDQggb9cOVBj2UXaoRMFuh4sEgBCAvx48vIBdI8N48mPN5FXXMFfrhxAzziNZRdxFxrlIj8yxnD7mT146bqhZOeXce5fl3LXvO/I2nPQ6dJEpBl0hS4/cUG/TgzvNp5ZX+3g1W928sH6vQxOjuSiAZ25sH8CnSKCnC5RRI5BfehyQqUVNcxftYv31uwha+9BjIHrRiTz2wv7qo9dxAEtuilqjJkFXAQUWGv7HWN7BPAakEzDFf9frLWzmypKge5+thUeYu7yHF75Zie9O4XzwqTB6mMXaWMtfVL0FeCCE2y/C8iy1g4ExgFPGWMCTrZIaf96xIbx2CWn8cqUYRSWVXHx81+zIDPP6bJEpFGTgW6tXQocOFETINw0DFwOa2xb65rypD0alxbHR/ecwaCkSH791loeXbSeqto6p8sS8XquGOXyAtAH2AOsB+6x1h5z0hBjzFRjTIYxJqOwUIsfu7O4DkHMvWU4t53ZnXkrd3H1P1awt1Rrn4o4yRWBfj6wBugMDAJeMMZ0OFZDa+10a226tTY9NjbWBbsWJ/n5+vDwhD68dN0QsvPLuHb6CgqPmJ9dRNqWKwJ9CrDQNtgK7AB6u+B7xU1M6J/A3F+MIP9gFTfNXsXByhqnSxLxSq4I9F3A2QDGmHggDdjugu8VNzIkOYqXrh/C5n1lTJ2TQWWN+tRF2lqTgW6MmQ8sB9KMMXnGmFuMMbcbY25vbDINGG2MWQ98DjxorS1qvZKlvRqXFsdTVw1kxfYDPLJwvdPliHidJp8UtdZe28T2PcB5LqtI3Nqlg7qwrfAwz32ezYUDEji7T7zTJYl4Dc3lIi5391k96d0pnEcXbVB/ukgbUqCLywX4+fDk5QMoKKvkjx9tcrocEa+hQJdWMTApkl+c0Z1/rtzF8m37nS5HxCso0KXV3HdOKikdQ3ho4ToqqjXqRaS1KdCl1QQH+PK/Px9Azv5y/vrZFqfLEfF4CnRpVaN6dGTSiGRmLNvO2twSp8sR8WgKdGl1D0/oTXyHIB5YsI7q2mNO8yMiLqBAl1YXHuTP45f1Y3N+GS8u2ep0OSIeS4EubWJ873guG9yF57/I5qtsPUgs0hoU6NJm/vCzfvSKC+fu+d+Re6Dc6XJEPI4CXdpMaKAf028cSn295dY5GZRXax0UEVdSoEub6toxlOcnDWFLfhkPvq0JvERcSYEube7M1FjuPSeV99fu4YtN+U6XI+IxFOjiiNvP7EH32FB+/36W1iMVcREFujgiwM+Hxy4+jZ37y5mxbIfT5Yh4BAW6OGZsaiznnxbPC19sZU+JFpgWaSkFujjqtxf2pd5aHv9go9OliLg9Bbo4Kik6hDvH9eSD9Xt1g1SkhRTo4rg7xvUgNT6MRxZqhSORllCgi+MC/Hz40xUDKSir5H8/VNeLyKlSoEu7MCgpklvP6M78Vbma60XkFCnQpd2479xUusWE8uDb6zhwuNrpckTcjgJd2o0gf1+eumogRYeqmDJ7FYeqNNeLyMlQoEu7MiQ5ihcnDWHDnoPcNjdDT5GKnAQFurQ75/SN50+XD+Drrfu5a95qvtlWRGmFRr+INMXP6QJEjuXyoYmUVtQw7YMsPtvYMD69e0wot47tzpVDE/Hz1bWIyNGMtdaRHaenp9uMjAxH9i3uY/+hKr7fc5ANe0r5NCuf1btK6BkXxq/PS2NAYgSRIf4E+/tijHG6VJE2YYzJtNamH3ObAl3chbWWf2Xl8+RHm9hedPjH94P8fbh8SCL3nNOLuPAgAHL2H2bR6t3EhAVydp84EiKCnSpbxKUU6OJRaurqWbqlkIKyKkorathacIh3Vu/G39eHG0Z1JTu/jH9vKeTIf9r9unRgfO94xqXFMjAxEl+f9nVFv/9QFcEBvoQEqBdUTkyBLh5vR9Fh/vLJZj5Yv5eYsEAmjUhm0vBkyipr+HRjPp9vLGD1rmLqLUSF+DMuLY5z+8YzNjWWsEBnQ7ToUBVnP/UlVbV1nJUWx4T+CZzZK5aIEH9H65L2SYEuXiP/YCVRIQEE+P30pmnx4WqWZhfy782FLNlcQEl5DQG+PoxNjeHK9CTG947D34Gbrb99Zz3zV+Vy5dBEPt9UQGFZFQDdYkIZmBhBeJA/RYeqKDpURZ+EDjwysQ9B/r5tXqe0Dy0KdGPMLOAioMBa2+84bcYBzwD+QJG19symilKgi5Nq6+rJzCnmX1n5vL92DwVlVXQMDeDu8T2ZMqZbm9WRnV/GBc8u4/oRyfzPpf2oq7d8t6uYb3ceYG1uCWtzS6msrSMmLJDIYH8ycooZmBjBP25Ip1NEUJvVKe1HSwN9LHAImHOsQDfGRALfABdYa3cZY+KstQVNFaVAl/aitq6epdmFvLx0B8u37+f1qSMZ2b1jm+x7yuxVZOQU8+VvziI6NKDJ9p98v4/73lhDWKAf029MZ1BSZOsXKe3KiQK9yb8vrbVLgQMnaDIJWGit3dXYvskwF2lP/Hx9GN87npk3pdO1YwgPLFhHeXXrTzuwLLuQJZsL+eX4ns0Kc4DzT+vEwjtHE+Dnww0zV7LziNE+Iq7oMEwFoowx/zbGZBpjbjxeQ2PMVGNMhjEmo7Cw0AW7FnGdkAA//nT5AHYdKOfJjza16r6KD1czbXEWSdHBTB6dclKf7d2pA/NvHYmvj+H21zKpqNb0CNLAFYHuBwwFLgTOB35njEk9VkNr7XRrbbq1Nj02NtYFuxZxrRHdO3LT6BReXZ7D8m37W2UfG/ce5JIXv2JnUTm/v7QfgX4nf4MzKTqEZ64exOb8Mh5ZtB6nBjdI++KK8Vp5wH5r7WHgsDFmKTAQ2OKC7xZpcw9ckMaSzQX8vzfX8OZto0iKDnHZd3+4fi/3v7mW8CA/Xr9tJEOSo075u8alxXHfOak8/ekW4joE0iM2jKraehKjgjkrLc5lNYv7cMUV+rvA6cYYP2NMCDAC0LIz4rZCAvz423VDOFxVy7Uvr2B3SYVLvvfD9Xu5c9539EkIZ/EvT29RmP/g7rN6ck6feP7x5XYeWLCO372zgSmzv+XdNbtdULG4m+aMcpkPjANigHzgv2kYnoi19u+NbX4DTAHqgRnW2mea2rFGuUh7ty6vhOtmrCQqJIA3bhvZoukDvttVzLXTV9CvSwTzfjHCpePI6+stOQfK8fc1+Pv68Mt/rmbd7hIW3TmGPgkdXLYfaR/0YJHIKVqTW8INM1bi62sYmhxFvy4RjO7RkREnMawx90A5P3vxa0ID/Vh052g6hgW2YsVQUFbJxc9/RaCfL+/ffbqeOPUwLRq2KOLNBiVFMn/qSManxbHrQDnPf5HN1dNXMHf5zmZ9fmfRYW6avYraesvsKcNaPcwB4sKDeOn6oewtreDeN1brhqkX0UxAIk3o1yWCp68eBMDhqlrueX01v3v3e/x9fbhmePIxP1NXb5n11Q6e+nQz/j4+vDw5nR6xYW1W85DkKB6a0Idpi7PIyClmWEp0m+1bnKNAFzkJoYF+vHjdEKbOyeThReupt3BmWixhAX5YLFl7DrJudykfrt/LurxSzukTxx9+1t+Rx/SvHZ7E0//azFsZuQp0L6FAFzlJgX6+/OOGodzy6rc8smj9MdukdAzh2WsGccnAzo4tvhES4MfE/gl8sG4vj11ymqbm9QI6wyKnIMjfl5mTh/HvzQWUVtRwuKqOunpLaqdwBnSJIKqZj/K3tivTk3grM4+PN+zj50MSnS5HWpkCXeQUBfn7ckG/BKfLOKFhKVEkR4ewIDNPge4FNMpFxIMZY7hiaCLfbNtPXnG50+VIK1Ogi3i4nw/pAsDC7/T0qKdToIt4uMSoEEb36MiCzDyNSfdwCnQRL3BVehK7DpTzyff7nC5FWpECXcQLXDQggV5xYfzvR5uorq13uhxpJQp0ES/g5+vDoxf2IWd/OXOaOW2BuB8FuoiXGJcWx9jUWJ77PJviw9VOlyOtQIEu4kUendiHQ1W1PPt5NvtKK/k0K5/pS7exLLuQyhotZefu9GCRiBdJ6xTONcOTeeWbnbzyzc7/2Bbg58PwlGgemdiHvp01j7o7UqCLeJnfnJdGsL8vSVHB9E+MIKVjKOt2l/J1dhHvrt3DtS+vYN4vRtCvS8RPPltdW88bGbmE+Pty4YAEly7UIS2nBS5E5Ee5B8q5ZvoKyiprmHvLCAYmRf64bfO+Mv7fm2v4fs9BAKJDA5g0PJkpY1LaZJ53aaAVi0Sk2fKKy7n25RWUHK7hwgEJhAb6UVtXz/xVuXQI9uPxy/oTHujH7G928tnGfAYnRfL2HaMdm1XS25wo0NXlIiL/ITEqhDemjuLeN9awZHMBh6vqKK+u5YJ+nZh2ab8fr8ZH94xh/qpdPLxwPZ9vLOCcvvEOVy66QheRJllrj3kFXlNXz3l/XUqgnw8f/uoMfHx0ld7atKaoiLTI8bpT/H19uO/cVDbtK+P9dXvauCo5mgJdRFrkov4J9EnowNOfbqGmTtMKOEmBLiIt4uNj+M35qeTsL+fNjFyny/FqCnQRabGz0uIYnhLNEx9sZMPuUqfL8VoKdBFpMWMMz08aTGRIADfNXsWu/VodyQkKdBFxifgOQbx683Bq6y03zlpJ0aEqp0vyOhq2KCIulZlTzHUzVhDg60OfhA6kxoeTEhNKXHggseGBdI8NJS48yOky3ZYeLBKRNjO0axRzbxnB25l5bMkv453Vuymrqv1xe4CfD3/4WT+uSk9ysErPpEAXEZcblhLNsJRooOGhpJLyGooOVVFQVsWLS7bywIJ1rMkt4b8v7kugnyb4chUFuoi0KmMMUaEBRIUG0Cs+nBHdovnzvzbzjy+3883WIjpHBuPn60Ognw+Rwf5EhvgTFx7EOX3j6RYT6nT5bqXJPnRjzCzgIqDAWtvvBO2GAcuBa6y1C5rasfrQRbzbxxv2MW9lDpU1dVTXWapq6iitqKGkvIaKxsU2BiZFctmgzlyRnkRY4P9df5aUV/Paihy2FR5mX2klBw5Xc9WwJG4ek+Lxk4S1aLZFY8xY4BAw53iBbozxBT4FKoFZCnQRaYl9pZW8v3YPi1bvJmvvQaJC/Jk6tgfXDk9iQWYez32eTVlVLZ0jgukUEURtvWVtbgmTR3Xlvy4+DV8PnlOmxdPnGmNSgMUnCPR7gRpgWGM7BbqIuMTqXcU881k2X24pxBiwFs7oFcOjF/ahd6eGlZXq6y1PfLiRGV/t4Ly+8Tx7zWCCAzyzb75VR7kYY7oAlwFn0RDoIiIuMzg5ildvHk5mTjHvrtnN+N5xjEuL+482Pj6G317Uly5Rwfx+cRa3zslg1k3DCPDzrkdtXHFT9BngQWttfVN9V8aYqcBUgOTkZBfsWkS8xdCuUQztGnXCNlPGdCM00I8HFqzjgQVrefqqQV41pa8rAj0deL0xzGOAicaYWmvtO0c3tNZOB6ZDQ5eLC/YtIvIfrkpPorCsij9/spm4DkE8MrGP0yW1mRYHurW22w+/G2NeoaEP/Z2Wfq+IyKm6c1wP9pVWMn3pdpKigrlhVIrTJbWJJgPdGDMfGAfEGGPygP8G/AGstX9v1epERE6BMYbHLjmN3OJyHv9wI2emxpHcMcTpslqd5nIREY+1p6SCc5/+kiFdo5hz83CPGKOuJehExCt1jgzmwQm9WZZdxKLVu50up9Up0EXEo10/oitDkiOZtjiL/R4+pa8CXUQ8mo+P4Y+XD+BQVS3/836W0+W0KgW6iHi81Phw7j6rF++t3cPidXtc9r2VNXV8lpXP4x9kcekLX5H22494x8GuHc22KCJe4a6zevDF5gIeXbSB9K7RdIpo/iIb/1y5iz99solhKdGMS4ulR2wYH67fyzurd3OwspYAXx8GJUXSKz6M3yxYS2x4IGN6xrTi0RybRrmIiNfYXniIic8tY1hKdLNHvazYvp/rZ6ykZ1wYZZW17C6pACDQz4fzT+vE5UMTGdEtmiB/X0orarjq78vZU1LBW3eM+nGuGVdq8eRcrUGBLiJOmLsih9+9s4HHLu7LTWO6nbBtXnE5l7zwNVEh/rxz1xjCAv3YWnCIrQWHGN0zhohg/598Zk9JBT//2zcATL9xKAMSI3/cVllTx6LVu+mT0IFBSZE/+WxzaAk6EZFG149IZsmmAn6/OIuwIH+uGJp4zHYV1XXcNjeTmrp6Xr4xnfCghvDuFR9Or/jw435/58hgZk8ZxqSXV3DJC19zRq8Ybh7TjTW5Jby2Iof9h6u55fRupxzoJ6IrdBHxOuXVtUydk8lXW4t44rL+TBrx08kCH1iwlrcy85g1eRhn9Y47xrecWFllDfNW7mLGsh0UNQ6XPKdPHLec3p2R3aNP+SEnXaGLiBwhJMCPGZPTueO1TB5ZtJ6KmjpuOf3/ul8+3rCXNzPyuOusHqcU5gDhQf7cfmYPbhqdwpJNBfSKD6dnXJirDuGYNGxRRLxSkL8v/7ghnQtO68S0xVk8/kEW9fWWfaWVPLRwPQMSI7j3nFSX7GdC/4RWD3PQFbqIeLEAPx9evG4Iv3//e15etoO84grKKmupqqnnmasH4e/rXte8CnQR8Wq+Pg0zMyZFh/D4hxuxFp64rD/dY1v/itrVFOgi4vWMMfzijO50iwll074yrh2e5HRJp0SBLiLS6Ow+8ZzdJ97pMk6Ze3UQiYjIcSnQRUQ8hAJdRMRDKNBFRDyEAl1ExEMo0EVEPIQCXUTEQyjQRUQ8hGPT5xpjCoGcU/x4DFDkwnLchTcetzceM3jncXvjMcPJH3dXa23ssTY4FugtYYzJON58wJ7MG4/bG48ZvPO4vfGYwbXHrS4XEREPoUAXEfEQ7hro050uwCHeeNzeeMzgncftjccMLjxut+xDFxGRn3LXK3QRETmKAl1ExEO4XaAbYy4wxmw2xmw1xjzkdD2twRiTZIxZYozJMsZ8b4y5p/H9aGPMp8aY7Mb/Rjlda2swxvgaY1YbYxY3vu5mjFnZeM7fMMYEOF2jKxljIo0xC4wxm4wxG40xo7zhXBtj7mv8973BGDPfGBPkiefaGDPLGFNgjNlwxHvHPL+mwXONx7/OGDPkZPblVoFujPEFXgQmAH2Ba40xfZ2tqlXUAvdba/sCI4G7Go/zIeBza20v4PPG157oHmDjEa+fBP5qre0JFAO3OFJV63kW+Nha2xsYSMOxe/S5NsZ0AX4FpFtr+wG+wDV45rl+BbjgqPeOd34nAL0af6YCL53Mjtwq0IHhwFZr7XZrbTXwOnCpwzW5nLV2r7X2u8bfy2j4P3gXGo711cZmrwI/c6TAVmSMSQQuBGY0vjbAeGBBYxOPOm5jTAQwFpgJYK2tttaW4AXnmoYlMIONMX5ACLAXDzzX1tqlwIGj3j7e+b0UmGMbrAAijTEJzd2XuwV6FyD3iNd5je95LGNMCjAYWAnEW2v3Nm7aB7jv4ofH9wzwAFDf+LojUGKtrW187WnnvBtQCMxu7GaaYYwJxcPPtbV2N/AXYBcNQV4KZOLZ5/pIxzu/Lco4dwt0r2KMCQPeBu611h48cpttGG/qUWNOjTEXAQXW2kyna2lDfsAQ4CVr7WDgMEd1r3jouY6i4Wq0G9AZCOWn3RJewZXn190CfTeQdMTrxMb3PI4xxp+GMJ9nrV3Y+Hb+D39+Nf63wKn6WskY4BJjzE4autPG09C/HNn4Zzl43jnPA/KstSsbXy+gIeA9/VyfA+yw1hZaa2uAhTScf08+10c63vltUca5W6B/C/RqvBMeQMNNlPccrsnlGvuNZwIbrbVPH7HpPWBy4++TgXfburbWZK192FqbaK1NoeHcfmGtvQ5YAlzR2Myjjttauw/INcakNb51NpCFh59rGrpaRhpjQhr/vf9w3B57ro9yvPP7HnBj42iXkUDpEV0zTbPWutUPMBHYAmwDHnW6nlY6xtNp+BNsHbCm8WciDf3JnwPZwGdAtNO1tuL/BuOAxY2/dwdWAVuBt4BAp+tz8bEOAjIaz/c7QJQ3nGvgf4BNwAZgLhDoiecamE/DfYIaGv4iu+V45xcwNIzk2wasp2EUULP3pUf/RUQ8hLt1uYiIyHEo0EVEPIQCXUTEQyjQRUQ8hAJdRMRDKNBFRDyEAl1ExEP8f40kP6iq8lahAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x shape is  (128, 32, 32, 3)\n",
      "train pred is \n",
      " [9 9 2 1 7 1 3 5 3 6]\n",
      "train y  is \n",
      " [9 9 2 1 7 1 3 5 3 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(train_X[:data_size])\n",
    "train_accuracy = multiclass_accuracy(train_pred, train_y[:data_size])\n",
    "print('Neural net train set accuracy: %f' % (train_accuracy, ))\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "\n",
    "number = 10\n",
    "print(\"train x shape is \", train_X[:data_size].shape)\n",
    "train_pred = model.predict(train_X[:number])\n",
    "print(\"train pred is \\n\", train_pred)\n",
    "print(\"train y  is \\n\", train_y[:number])\n",
    "\n",
    "for i in range(number):\n",
    "        plt.subplot(1, number, i+1)        \n",
    "        image = (train_X[i]+1)/2\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "# print(\"test pred is \\n\", test_pred[:number])\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is  (2, 4, 3, 3)\n",
      "transformed X shape is  (3, 3, 4, 2)\n",
      "[[13.  9.  3.]\n",
      " [ 2. 22.  2.]]\n",
      "1 1\n",
      "[3 4 3 4]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 1, 0.0], [2.0, 1, 1.0], [9.0, 1, 1.0]],\n",
    "               [[0.0, 1,  -1.0], [-1.0, 1,  -2.0],[2.0, 1, 1.0]], \n",
    "               [[0.0, 1,  -1.0], [-5.0, 1,  -2.0],[2.0, 9, 1.0]],\n",
    "               [[0.0, 1,  3.0], [13.0, 1,  -2.0],[2.0, 1, 1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1, 1.0], [1.0, 1,  -1.0], [2.0, 1, 1.0]],\n",
    "               [[-2.0, 1,  2.0], [-1.0, 1, 0.0], [2.0, 1, 1.0]],\n",
    "               [[-2.0, 1,  2.0], [-1.0, 1, 0.0], [2.0, 1, 1.0]],\n",
    "               [[0.0, 1,  -1.0], [-1.0, 22,  -2.0],[2.0, 1, 1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# A = np.array([[[3,3], [2,2]], [[3,3,], [1,1]]])\n",
    "x_off= 1\n",
    "y_off = 1\n",
    "Y = X[:, x_off:2+x_off,  y_off:2 + y_off, :]\n",
    "print(\"X shape is \", X.shape)\n",
    "# print(\"Y shape is \", Y.shape)\n",
    "# print(X)\n",
    "# print(X.ndim)\n",
    "# print(\"Y is\\n\", Y)\n",
    "# print(\"A\\n\", A)\n",
    "print(\"transformed X shape is \", X.T.shape)\n",
    "\n",
    "b = [1000, 100, 30]\n",
    "# print(X + b)\n",
    "maxes = X.max(axis=(1, 2))\n",
    "# indices = X.argmax(axis=(1, 2))\n",
    "# indices = X.argmax(axis= (1,2))\n",
    "x, y = np.argwhere(maxes==maxes.max())[0]\n",
    "print(maxes)\n",
    "print(x, y)\n",
    "# print(maxes[ind[0], ind[1]])\n",
    "# print(maxes.shape)\n",
    "\n",
    "a = np.array([3,4,3,4,5])\n",
    "print(a[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
